
# UIT Data Science Challenge 2025: PhÃ¡t hiá»‡n áº¢o giÃ¡c trong LLM Tiáº¿ng Viá»‡t

**Team Name:** [Äiá»n TÃªn Äá»™i Cá»§a Báº¡n]

**Track:** Hallucination Detection

## ğŸ“– Tá»•ng quan (Overview)

Repository nÃ y chá»©a mÃ£ nguá»“n giáº£i phÃ¡p chÃ­nh thá»©c cho cuá»™c thi **UIT Data Science Challenge 2025**. Má»¥c tiÃªu cá»§a dá»± Ã¡n lÃ  xÃ¢y dá»±ng há»‡ thá»‘ng tá»± Ä‘á»™ng phÃ¡t hiá»‡n áº£o giÃ¡c (Hallucination) trong cÃ¡c mÃ´ hÃ¬nh ngÃ´n ngá»¯ lá»›n tiáº¿ng Viá»‡t, phÃ¢n loáº¡i Ä‘áº§u ra thÃ nh 3 nhÃ£n:

1. **No Hallucination (0):** Pháº£n há»“i chÃ­nh xÃ¡c, thÃ´ng tin hoÃ n toÃ n dá»±a trÃªn ngá»¯ cáº£nh Ä‘Æ°á»£c cung cáº¥p.
2. **Intrinsic Hallucination (1):** Pháº£n há»“i mÃ¢u thuáº«n hoáº·c bÃ³p mÃ©o thÃ´ng tin so vá»›i ngá»¯ cáº£nh.
3. **Extrinsic Hallucination (2):** Pháº£n há»“i chá»©a thÃ´ng tin bá»• sung khÃ´ng cÃ³ cÄƒn cá»© trong ngá»¯ cáº£nh.

ChÃºng tÃ´i Ä‘á» xuáº¥t phÆ°Æ¡ng phÃ¡p **Two-Stage Pipeline** (Quy trÃ¬nh 2 giai Ä‘oáº¡n) káº¿t há»£p giá»¯a trÃ­ch xuáº¥t minh chá»©ng (Evidence Extraction) báº±ng nhÃ£n yáº¿u vÃ  phÃ¢n loáº¡i ngá»¯ nghÄ©a (Semantic Classification) vá»›i cÆ¡ cháº¿ Attention Pooling.

## ğŸš€ PhÆ°Æ¡ng phÃ¡p tiáº¿p cáº­n (Methodology)

Giáº£i phÃ¡p Ä‘Æ°á»£c chia lÃ m 2 giai Ä‘oáº¡n chÃ­nh Ä‘á»ƒ xá»­ lÃ½ váº¥n Ä‘á» ngá»¯ cáº£nh dÃ i (Long Context) vÃ  nhiá»…u:

### Giai Ä‘oáº¡n 1: CE Gate Pipeline (TrÃ­ch xuáº¥t minh chá»©ng)

Thay vÃ¬ Ä‘Æ°a toÃ n bá»™ ngá»¯ cáº£nh (Context) vÃ o mÃ´ hÃ¬nh phÃ¢n loáº¡i, chÃºng tÃ´i lá»c ra cÃ¡c Ä‘oáº¡n vÄƒn quan trá»ng nháº¥t.

* **Teacher Model:** Sá»­ dá»¥ng `xlm-roberta-base` lÃ m Cross-Encoder Ä‘á»ƒ cháº¥m Ä‘iá»ƒm sá»± liÃªn quan giá»¯a (Prompt + Response) vÃ  tá»«ng phÃ¢n Ä‘oáº¡n (Span) trong Context.
* **Weak Supervision:** Sá»­ dá»¥ng cÃ¡c luáº­t heuristic (khá»›p sá»‘ liá»‡u, tá»« phá»§ Ä‘á»‹nh, overlap) Ä‘á»ƒ táº¡o nhÃ£n giáº£ láº­p huáº¥n luyá»‡n Teacher.
* **Dual-Beam Packer:** Thuáº­t toÃ¡n chá»n lá»c minh chá»©ng thÃ´ng minh, cÃ¢n báº±ng giá»¯a thÃ´ng tin **á»¦ng há»™** (Support) vÃ  thÃ´ng tin **MÃ¢u thuáº«n** (Conflict) Ä‘á»ƒ Ä‘áº£m báº£o mÃ´ hÃ¬nh nhÃ¬n tháº¥y Ä‘Æ°á»£c cáº£ hai khÃ­a cáº¡nh cá»§a áº£o giÃ¡c.

### Giai Ä‘oáº¡n 2: Final Classifier (PhÃ¢n loáº¡i cuá»‘i cÃ¹ng)

* **Backbone:** Sá»­ dá»¥ng `vinai/phobert-large` (State-of-the-art cho tiáº¿ng Viá»‡t).
* **Attention Pooling:** Thay vÃ¬ dÃ¹ng token `[CLS]`, chÃºng tÃ´i dÃ¹ng vector cá»§a (Prompt + Response) lÃ m *Query* Ä‘á»ƒ "chÃº Ã½" (attend) vÃ o cÃ¡c token quan trá»ng trong Minh chá»©ng (*Key/Value*).
* **Feature Fusion:** Káº¿t há»£p vector vÄƒn báº£n vá»›i cÃ¡c chá»‰ sá»‘ ngá»¯ nghÄ©a (`support_mass`, `conflict_mass`) tá»« Giai Ä‘oáº¡n 1.
* **Training Tricks:** Weighted Focal Loss (xá»­ lÃ½ máº¥t cÃ¢n báº±ng máº«u), R-Drop, FGM (Adversarial Training).

## ğŸ“‚ Cáº¥u trÃºc dá»± Ã¡n (Project Structure)

```text
uit-dsc-hallucination-detection/
â”œâ”€â”€ configs/                        # Chá»©a cÃ¡c file tham sá»‘ cáº¥u hÃ¬nh vÃ  mapping
â”‚   â”œâ”€â”€ labels.json                 # Tá»« output ce_gate (Label mapping)
â”‚   â”œâ”€â”€ ce_temp.json                # Tá»« output ce_gate (temp.json - Ä‘á»•i tÃªn cho rÃµ)
â”‚   â”œâ”€â”€ cls_temp.json               # Tá»« output classifier
â”‚   â””â”€â”€ final_meta.json             # Tá»« output classifier (Hyperparams)
â”‚
â”œâ”€â”€ data/                           # Quáº£n lÃ½ dá»¯ liá»‡u (DÃ¹ng .gitignore cho file lá»›n)
â”‚   â”œâ”€â”€ raw/                        # Dá»¯ liá»‡u gá»‘c cuá»™c thi (vihallu-train.csv...)
â”‚   â”œâ”€â”€ interim/                    # Dá»¯ liá»‡u trung gian (Stage 1 táº¡o ra)
â”‚   â”‚   â”œâ”€â”€ ce_pairs_balanced.csv   # DÃ¹ng huáº¥n luyá»‡n Teacher
â”‚   â”‚   â”œâ”€â”€ train_v3_semantic.csv   # PhÃ¢n tÃ­ch ngá»¯ nghÄ©a
â”‚   â”‚   â””â”€â”€ val_v3_semantic.csv
â”‚   â”‚
â”‚   â””â”€â”€ processed/                  # Dá»¯ liá»‡u Ä‘Ã£ xá»­ lÃ½ quan trá»ng (Input cho Stage 2)
â”‚       â”œâ”€â”€ hybrid_train_v3_coverage_with_mass.csv  
â”‚       â”œâ”€â”€ hybrid_val_v3_coverage_with_mass.csv    
â”‚       â””â”€â”€ hybrid_test_v3_coverage_with_mass.csv   
|
â”œâ”€â”€ models/                         # NÆ¡i chá»©a trá»ng sá»‘ (KhÃ´ng push lÃªn Git, chá»‰ lÆ°u link)
â”‚   â”œâ”€â”€ teacher/
â”‚   â”‚   â””â”€â”€ teacher.pt              # [Táº£i tá»« Kaggle Dataset 1](https://www.kaggle.com/datasets/honghien123/ce-gate-pipeline-v3-3)
â”‚   â””â”€â”€ classifier/
â”‚       â”œâ”€â”€ final_model.pt          # [Táº£i tá»« Kaggle Dataset 2](https://www.kaggle.com/datasets/honghien123/artefactmodel-ce-gate-pipeline-v3)
â”‚       â””â”€â”€ final_best.pt           # [Táº£i tá»« Kaggle Dataset 2](https://www.kaggle.com/datasets/honghien123/artefactmodel-ce-gate-pipeline-v3)
|
â”œâ”€â”€ notebooks/                      # MÃ£ nguá»“n cháº¡y thá»­ nghiá»‡m
â”‚   â”œâ”€â”€ 01_ce_gate_pipeline.ipynb
â”‚   â””â”€â”€ 02_final_classifier.ipynb
â”‚
â”œâ”€â”€ reports/                        # BÃ¡o cÃ¡o vÃ  chá»‰ sá»‘ Ä‘Ã¡nh giÃ¡
â”‚   â”œâ”€â”€ gate_report.json            # Tá»« output ce_gate
â”‚   â”œâ”€â”€ evaluation_metrics.json     # Tá»« output classifier
â”‚   â””â”€â”€ MANIFEST.json               # Danh sÃ¡ch artifact
â”‚
â”œâ”€â”€ submissions/                    # Káº¿t quáº£ ná»™p bÃ i
â”‚   â”œâ”€â”€ submit.csv                  # Káº¿t quáº£ cuá»‘i cÃ¹ng (cÃ³ temp scaling)
â”‚   â”œâ”€â”€ submit_no_temp.csv          # Káº¿t quáº£ tham kháº£o (khÃ´ng temp)
â”‚   â””â”€â”€ archive/                    # LÆ°u cÃ¡c file .zip
â”‚       â”œâ”€â”€ submit.zip
â”‚       â””â”€â”€ submit_no_temp.zip
â”‚
â”œâ”€â”€ scripts/                        # Scripts tiá»‡n Ã­ch
â”‚   â””â”€â”€ download_artifacts.sh       # Script táº£i model tá»« Kaggle vá» folder models/
â”‚
â”œâ”€â”€ .gitignore                      # Cháº·n file náº·ng
â”œâ”€â”€ README.md                       # HÆ°á»›ng dáº«n dá»± Ã¡n
â””â”€â”€ requirements.txt                # ThÆ° viá»‡n cáº§n thiáº¿t

```

## ğŸ› ï¸ CÃ i Ä‘áº·t & HÆ°á»›ng dáº«n sá»­ dá»¥ng

### 1. Chuáº©n bá»‹ mÃ´i trÆ°á»ng

YÃªu cáº§u Python 3.10+ vÃ  PyTorch cÃ³ há»— trá»£ CUDA.

```bash
# Clone repository
git clone https://github.com/[username]/uit-dsc-hallucination-detection.git
cd uit-dsc-hallucination-detection

# CÃ i Ä‘áº·t thÆ° viá»‡n
pip install -r requirements.txt

```

### 2. Táº£i Dá»¯ liá»‡u & Trá»ng sá»‘ MÃ´ hÃ¬nh

Do giá»›i háº¡n dung lÆ°á»£ng cá»§a GitHub, cÃ¡c file trá»ng sá»‘ mÃ´ hÃ¬nh (`.pt` ~3GB) vÃ  dá»¯ liá»‡u huáº¥n luyá»‡n lá»›n Ä‘Æ°á»£c lÆ°u trá»¯ trÃªn Kaggle. Báº¡n cáº§n cháº¡y script sau Ä‘á»ƒ táº£i chÃºng vá» Ä‘Ãºng thÆ° má»¥c:

```bash
# Cáº¥p quyá»n thá»±c thi (náº¿u cáº§n)
chmod +x scripts/download_artifacts.sh

# Cháº¡y script táº£i dá»¯ liá»‡u
python scripts/download_models.py
```

*LÆ°u Ã½: Cáº§n cáº¥u hÃ¬nh Kaggle API Key (`~/.kaggle/kaggle.json`) Ä‘á»ƒ script hoáº¡t Ä‘á»™ng.*

### 3. Quy trÃ¬nh Huáº¥n luyá»‡n & Inference

**BÆ°á»›c 1: Cháº¡y Giai Ä‘oáº¡n 1 (Evidence Extraction)**
Má»Ÿ notebook `notebooks/01_ce_gate_pipeline.ipynb`.

* **Input:** `data/raw/vihallu-train.csv`
* **Output:** Dá»¯ liá»‡u Ä‘Ã£ lá»c minh chá»©ng táº¡i `data/processed/hybrid_train_v3_coverage_with_mass.csv`.

**BÆ°á»›c 2: Cháº¡y Giai Ä‘oáº¡n 2 (Training & Prediction)**
Má»Ÿ notebook `notebooks/02_final_classifier.ipynb`.

* **Input:** Dá»¯ liá»‡u processed tá»« BÆ°á»›c 1.
* **Output:** Model `final_model.pt` vÃ  file ná»™p bÃ i `submissions/submit.csv`.

## ğŸ“Š Káº¿t quáº£ (Results)

Hiá»‡u suáº¥t mÃ´ hÃ¬nh trÃªn táº­p Validation (Ä‘Æ°á»£c trÃ­ch xuáº¥t tá»« `evaluation_metrics.json`):

| Metric | Score | Ghi chÃº |
| --- | --- | --- |
| **Final Macro F1** | **0.880** | Stage 2 Classifier |
| **Accuracy** | **0.879** | Stage 2 Classifier |
| **Teacher F1** | 0.974 | Stage 1 (Weak-label task) |

**Chi tiáº¿t tá»«ng lá»›p (Per-class Performance):**

| Class | Precision | Recall | F1-Score |
| --- | --- | --- | --- |
| **No Hallucination** | 0.97 | 0.96 | **0.96** |
| **Intrinsic** | 0.85 | 0.85 | 0.85 |
| **Extrinsic** | 0.82 | 0.83 | 0.82 |

## ğŸ“œ Giáº¥y phÃ©p

MÃ£ nguá»“n Ä‘Æ°á»£c phÃ¢n phá»‘i dÆ°á»›i giáº¥y phÃ©p **MIT**. Dá»¯ liá»‡u vÃ  cÃ¡c trá»ng sá»‘ mÃ´ hÃ¬nh tuÃ¢n theo giáº¥y phÃ©p **CC-BY-SA 4.0** theo quy Ä‘á»‹nh cá»§a cuá»™c thi UIT Data Science Challenge 2025.
