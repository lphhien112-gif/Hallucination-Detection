{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":13246709,"sourceType":"datasetVersion","datasetId":8348762},{"sourceId":13251834,"sourceType":"datasetVersion","datasetId":8397164},{"sourceId":13267887,"sourceType":"datasetVersion","datasetId":8407914}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip -q install \"transformers>=4.40.0\" \"accelerate>=0.31.0\" \"scikit-learn>=1.3.0\"","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os, re, math, random, json, unicodedata\nfrom dataclasses import dataclass\nfrom typing import List, Tuple\nfrom collections import Counter\nfrom inspect import signature\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\nfrom sklearn.metrics import f1_score, accuracy_score, roc_auc_score\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.linear_model import LogisticRegression\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset, DataLoader\nfrom transformers import AutoTokenizer, AutoModel, get_linear_schedule_with_warmup\n\n@dataclass\nclass CFG:\n    # raw data\n    train_csv: str = \"/kaggle/input/dsc-uit-2025/vihallu-train.csv\"\n    test_csv:  str = \"/kaggle/input/dsc-uit-2025/vihallu-private-test.csv\"\n    id_col:    str = \"id\"\n    ctx_col:   str = \"context\"\n    prm_col:   str = \"prompt\"\n    rsp_col:   str = \"response\"\n    lab_col:   str = \"label\"\n\n    # packer/classifier tokenizer ngân sách 1 chuỗi\n    tok_name: str = \"vinai/phobert-large\"\n    max_len_single: int = 256\n\n    # CE teacher (NLI 3 lớp: Entail / Neutral / Contradict)\n    ce_backbone: str = \"xlm-roberta-base\"\n    ce_max_len: int = 256\n    ce_bs: int = 32\n    ce_epochs: int = 4\n    ce_lr: float = 2e-5\n    ce_wd: float = 0.01\n    ce_warmup: float = 0.1\n    ce_dropout: float = 0.1\n\n    # Packer (dual-beam ưu tiên hỗ trợ + mâu thuẫn)\n    span_sizes: Tuple[int,...] = (2,3,4)\n    stride_sent: int = 1\n    top_span_pool: int = 48\n    boost_num: float = 0.10\n    boost_neg: float = 0.05\n    conflict_target_ratio: float = 0.40\n\n    # Gate ngưỡng an toàn\n    auc_intrinsic_min: float = 0.74\n    auc_extrinsic_min: float = 0.66\n    meta_f1_min: float = 0.74\n    rl_median_min: float = 0.20\n\n    # IO\n    outdir: str = \"/kaggle/working/ce_gate_pipeline_v3\"\n\n    # misc\n    seed: int = 42\n    valid_ratio: float = 0.10\n    device: str = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\nos.makedirs(CFG.outdir, exist_ok=True)\n\ndef seed_all(s=CFG.seed):\n    random.seed(s); np.random.seed(s)\n    torch.manual_seed(s)\n    if torch.cuda.is_available(): torch.cuda.manual_seed_all(s)\nseed_all()\n\n# label maps\nLABEL2ID = {\"no\":0, \"intrinsic\":1, \"extrinsic\":2}\nID2LABEL = {v:k for k,v in LABEL2ID.items()}","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T07:11:26.357120Z","iopub.execute_input":"2025-10-05T07:11:26.357489Z","iopub.status.idle":"2025-10-05T07:11:39.139838Z","shell.execute_reply.started":"2025-10-05T07:11:26.357463Z","shell.execute_reply":"2025-10-05T07:11:39.139215Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Đọc raw + chuẩn hoá id -> str\ntrain_df = pd.read_csv(CFG.train_csv)\ntest_df  = pd.read_csv(CFG.test_csv)\nfor df in (train_df, test_df):\n    df[CFG.id_col] = df[CFG.id_col].astype(str)\n\nassert {CFG.ctx_col, CFG.prm_col, CFG.rsp_col, CFG.lab_col}.issubset(train_df.columns)\nassert {CFG.id_col, CFG.ctx_col, CFG.prm_col, CFG.rsp_col}.issubset(test_df.columns)\n\n# Tokenizers\ntok_pack = AutoTokenizer.from_pretrained(CFG.tok_name, use_fast=True)     # PhoBERT cho packer/classifier\ntok_ce   = AutoTokenizer.from_pretrained(CFG.ce_backbone, use_fast=True)  # XLM-R cho CE teacher\n\nS_SINGLE = tok_pack.num_special_tokens_to_add(pair=False)\nEFFECTIVE_MAX_SINGLE = CFG.max_len_single - S_SINGLE","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T07:11:39.140977Z","iopub.execute_input":"2025-10-05T07:11:39.141432Z","iopub.status.idle":"2025-10-05T07:11:43.949258Z","shell.execute_reply.started":"2025-10-05T07:11:39.141409Z","shell.execute_reply":"2025-10-05T07:11:43.948642Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/558 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5c88a29d4e41445cacce55f79b2c3d23"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d6afd672250143c9b761e54cebcd8a1b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"bpe.codes: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9582dbfcabc14c3faceaf652d74d1e87"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"393f044d85bf4d0ea2452cac3856be37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab616775d9fc4fe4a52c013dd22a4ae9"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/615 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a245d733d0d4a7b808eb9735938d1a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e38a715523da48e38d218f6869372c30"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/9.10M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fe76efc9d81b481c8a19fe1b929df265"}},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"SENT_SPLIT = re.compile(r\"(?<=[\\.\\!\\?。！？])\\s+|\\n+|(?<=\\u3002|\\uff01|\\uff1f)\\s+\", re.UNICODE)\nTOKEN_RE   = re.compile(r\"\\w+|[^\\w\\s]\", flags=re.UNICODE)\nNUM_RE     = re.compile(r'\\d+[.,]?\\d*')\nNEG_WORDS  = set([\"không\",\"chẳng\",\"chả\",\"chưa\",\"chẳng hề\",\"chẳng phải\",\"no\",\"not\",\"never\"])\n\ndef strip_diacritics(s: str) -> str:\n    nf = unicodedata.normalize(\"NFKD\", str(s))\n    return \"\".join([c for c in nf if not unicodedata.combining(c)])\n\ndef norm(s: str) -> str:\n    return strip_diacritics(str(s).strip().lower())\n\ndef toks(s: str) -> List[str]:\n    return [t for t in TOKEN_RE.findall(norm(s)) if t.strip()]\n\ndef sent_tokenize_vi(text: str) -> List[str]:\n    if not isinstance(text, str): return []\n    parts = [s.strip() for s in re.split(SENT_SPLIT, text.strip()) if s and s.strip()]\n    return parts\n\ndef build_idf(docs_tokens: List[List[str]]):\n    N = max(1, len(docs_tokens)); df = Counter(); total = 0\n    for dt in docs_tokens:\n        total += len(dt); df.update(set(dt))\n    avgdl = total / N\n    idf = {t: math.log((N - df_t + 0.5)/(df_t + 0.5) + 1) for t, df_t in df.items()}\n    return idf, max(1.0, avgdl)\n\ndef bm25_score(q_tokens, d_tokens, idf, avgdl, k1=1.2, b=0.75):\n    dq, dd = Counter(q_tokens), Counter(d_tokens)\n    dl = len(d_tokens); s = 0.0\n    for t in dq.keys():\n        f = dd.get(t, 0)\n        if f == 0: continue\n        idf_t = idf.get(t, 0.0)\n        denom = f + k1*(1 - b + b*dl/max(1.0, avgdl))\n        s += idf_t * (f*(k1+1)/denom)\n    return s\n\ndef char_trigrams(s: str):\n    s = norm(s)\n    return [s[i:i+3] for i in range(max(0, len(s)-2))] if s else []\n\ndef soft_char_overlap(A: List[str], B: List[str], tau=0.6) -> float:\n    s = 0.0\n    for q in A:\n        best=0.0; Aq=set(char_trigrams(q))\n        for u in B:\n            Bu=set(char_trigrams(u))\n            if not Aq and not Bu: continue\n            sim = len(Aq & Bu) / max(1, len(Aq | Bu))\n            best = max(best, sim)\n        if best >= tau: s += best\n    return s\n\ndef rouge_l_lcs(a_tokens, b_tokens):\n    A,B=a_tokens,b_tokens\n    m,n=len(A),len(B)\n    dp=[[0]*(n+1) for _ in range(m+1)]\n    for i in range(m):\n        Ai=A[i]\n        for j in range(n):\n            dp[i+1][j+1]= dp[i][j]+1 if Ai==B[j] else max(dp[i][j+1], dp[i+1][j])\n    lcs=dp[m][n]\n    prec=lcs/max(1,n); rec=lcs/max(1,m)\n    return 2*prec*rec/(prec+rec+1e-9)\n\ndef numbers(s: str): return set(NUM_RE.findall(norm(s)))\ndef has_neg(s: str) -> bool: return len(set(toks(s)) & NEG_WORDS) > 0\ndef join_pr(prompt, response): return f\"{str(prompt).strip()} [SEP] {str(response).strip()}\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T07:11:43.950002Z","iopub.execute_input":"2025-10-05T07:11:43.950270Z","iopub.status.idle":"2025-10-05T07:11:43.964938Z","shell.execute_reply.started":"2025-10-05T07:11:43.950251Z","shell.execute_reply":"2025-10-05T07:11:43.964384Z"}},"outputs":[],"execution_count":5},{"cell_type":"code","source":"def make_span_pool(context, prompt, response):\n    sents = sent_tokenize_vi(context)\n    if not sents: return []\n    R, P = toks(response), toks(prompt)\n    W = [toks(s) for s in sents]\n    idf, avgdl = build_idf(W)\n    spans = []\n    for k in CFG.span_sizes:\n        for st in range(0, len(sents), CFG.stride_sent):\n            en = min(len(sents), st+k)\n            if en <= st: continue\n            txt = \" \".join(sents[st:en]); ET = toks(txt)\n            s_lex = 0.5*(0.7*soft_char_overlap(R, ET) + 0.3*bm25_score(R, ET, idf, avgdl)) + \\\n                    0.5*(0.7*soft_char_overlap(P, ET) + 0.3*bm25_score(P, ET, idf, avgdl))\n            spans.append((st,en,txt,s_lex))\n    spans.sort(key=lambda x: x[3], reverse=True)\n    return spans[:CFG.top_span_pool]\n\ndef weak_label_for_span(label, response, span_text, s_lex, th_high=0.22, th_low=0.10):\n    r_nums = numbers(response); s_nums = numbers(span_text)\n    neg_diff = (has_neg(response) != has_neg(span_text))\n    num_mis  = (len(r_nums)>0) and (len(s_nums)>0) and (r_nums != s_nums)\n    rl = rouge_l_lcs(toks(response), toks(span_text))\n\n    if label == \"no\":\n        if rl >= th_high or s_lex >= th_high or (len(r_nums)>0 and r_nums.issubset(s_nums)):\n            return 0  # Entail\n        if num_mis or neg_diff:\n            return 2  # Contradict\n        return 1\n    elif label == \"intrinsic\":\n        if num_mis or neg_diff:\n            return 2\n        if rl >= (th_high + 0.05):\n            return 1  # tránh lệch Entail cho intrinsic\n        return 1\n    else:  # extrinsic\n        if rl < th_low and not (len(r_nums)>0 and r_nums.issubset(s_nums)):\n            return 1\n        if num_mis or neg_diff:\n            return 2\n        if rl >= th_high:\n            return 0\n        return 1\n\npairs = []\nfor _, row in tqdm(train_df.iterrows(), total=len(train_df), desc=\"[build CE pairs]\"):\n    spans = make_span_pool(row[CFG.ctx_col], row[CFG.prm_col], row[CFG.rsp_col])\n    PR = join_pr(row[CFG.prm_col], row[CFG.rsp_col])\n    for st,en,txt,sx in spans:\n        y = weak_label_for_span(row[CFG.lab_col], row[CFG.rsp_col], txt, sx)\n        pairs.append((PR, txt, y))\n\npairs_df = pd.DataFrame(pairs, columns=[\"A\",\"B\",\"y\"])\npairs_df.to_csv(os.path.join(CFG.outdir, \"ce_pairs_raw.csv\"), index=False)\n\nminc = pairs_df[\"y\"].value_counts().min()\nbal_df = pd.concat([pairs_df[pairs_df[\"y\"]==c].sample(minc, random_state=CFG.seed) for c in [0,1,2]],\n                   ignore_index=True).sample(frac=1.0, random_state=CFG.seed)\nbal_df.to_csv(os.path.join(CFG.outdir, \"ce_pairs_balanced.csv\"), index=False)\n\nprint(\"Pairs:\", len(pairs_df), \"| dist:\", pairs_df[\"y\"].value_counts().to_dict())\nprint(\"Balanced:\", len(bal_df), \"| dist:\", bal_df[\"y\"].value_counts().to_dict())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T07:11:43.966249Z","iopub.execute_input":"2025-10-05T07:11:43.966808Z","iopub.status.idle":"2025-10-05T07:38:30.743268Z","shell.execute_reply.started":"2025-10-05T07:11:43.966790Z","shell.execute_reply":"2025-10-05T07:38:30.742472Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"[build CE pairs]:   0%|          | 0/7000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"be96763237da4271be3ae238c57752e4"}},"metadata":{}},{"name":"stdout","text":"Pairs: 117567 | dist: {1: 43822, 0: 42475, 2: 31270}\nBalanced: 93810 | dist: {0: 31270, 1: 31270, 2: 31270}\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"class CEModel(nn.Module):\n    def __init__(self, name, num_labels=3, dropout=0.1):\n        super().__init__()\n        self.backbone = AutoModel.from_pretrained(name)\n        H = self.backbone.config.hidden_size\n        self.dropout = nn.Dropout(dropout)\n        self.cls = nn.Linear(H, num_labels)\n\n    def forward(self, enc):\n        allowed = set(signature(self.backbone.forward).parameters)\n        enc = {k: v for k, v in enc.items() if k in allowed}\n        out = self.backbone(**enc, return_dict=True).last_hidden_state[:,0,:]\n        out = self.dropout(out)\n        return self.cls(out)\n\nclass PairDS(Dataset):\n    def __init__(self, df): self.df=df.reset_index(drop=True)\n    def __len__(self): return len(self.df)\n    def __getitem__(self, i):\n        r = self.df.iloc[i]\n        enc = tok_ce(r[\"A\"], r[\"B\"], truncation=True, max_length=CFG.ce_max_len,\n                     padding=\"max_length\", return_tensors=\"pt\")\n        item = {k:v.squeeze(0) for k,v in enc.items()}\n        item[\"labels\"] = torch.tensor(int(r[\"y\"]), dtype=torch.long)\n        return item\n\ndef make_loader(df, bs, shuffle):\n    return DataLoader(PairDS(df), batch_size=bs, shuffle=shuffle, num_workers=0, pin_memory=True)\n\nmask = np.random.rand(len(bal_df)) < 0.9\ntr_ce, va_ce = bal_df[mask].reset_index(drop=True), bal_df[~mask].reset_index(drop=True)\ntr_loader = make_loader(tr_ce, CFG.ce_bs, True)\nva_loader = make_loader(va_ce, CFG.ce_bs*2, False)\n\nce = CEModel(CFG.ce_backbone, 3, CFG.ce_dropout).to(CFG.device)\nopt = torch.optim.AdamW(ce.parameters(), lr=CFG.ce_lr, weight_decay=CFG.ce_wd)\nsteps = len(tr_loader)*CFG.ce_epochs\nsch = get_linear_schedule_with_warmup(opt, int(steps*CFG.ce_warmup), steps)\nscaler = torch.amp.GradScaler('cuda', enabled=torch.cuda.is_available())\n\nbest_f1, ce_ckpt = -1.0, os.path.join(CFG.outdir, \"teacher.pt\")\nfor ep in range(1, CFG.ce_epochs+1):\n    ce.train(); losses=[]\n    pbar = tqdm(tr_loader, desc=f\"[CE train ep{ep}]\")\n    for batch in pbar:\n        batch = {k:v.to(CFG.device) for k,v in batch.items()}\n        opt.zero_grad(set_to_none=True)\n        with torch.amp.autocast('cuda', enabled=torch.cuda.is_available()):\n            logits = ce(batch)\n            loss = F.cross_entropy(logits, batch[\"labels\"])\n        scaler.scale(loss).backward()\n        scaler.step(opt); scaler.update(); sch.step()\n        losses.append(loss.item()); pbar.set_postfix(loss=np.mean(losses))\n\n    # eval\n    ce.eval(); preds=[]; trues=[]\n    with torch.no_grad():\n        for batch in va_loader:\n            lab = batch[\"labels\"].to(CFG.device)\n            enc = {k:v.to(CFG.device) for k,v in batch.items() if k!=\"labels\"}\n            logits = ce(enc)\n            pred = logits.argmax(-1)\n            preds += pred.detach().cpu().tolist()\n            trues += lab.detach().cpu().tolist()\n    f1 = f1_score(trues, preds, average=\"macro\")\n    acc= accuracy_score(trues, preds)\n    print(f\"[CE VAL] Macro-F1={f1:.4f} Acc={acc:.4f}\")\n    if f1 > best_f1:\n        best_f1 = f1\n        torch.save(ce.state_dict(), ce_ckpt)\n        print(\"  ↳ saved\", ce_ckpt)\nprint(\"CE best F1:\", best_f1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T07:38:30.744134Z","iopub.execute_input":"2025-10-05T07:38:30.744458Z","iopub.status.idle":"2025-10-05T09:09:16.651188Z","shell.execute_reply.started":"2025-10-05T07:38:30.744438Z","shell.execute_reply":"2025-10-05T09:09:16.650339Z"}},"outputs":[{"name":"stderr","text":"2025-10-05 07:38:46.303432: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1759649926.655949      36 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1759649926.748264      36 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.12G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5d85cecfaa564870a783d8a2a774a8d6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"[CE train ep1]:   0%|          | 0/2643 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30d1c586eb6b4696a8662943ce54eeab"}},"metadata":{}},{"name":"stdout","text":"[CE VAL] Macro-F1=0.9183 Acc=0.9185\n  ↳ saved /kaggle/working/ce_gate_pipeline_v3/teacher.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[CE train ep2]:   0%|          | 0/2643 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7c6c2ccc1fb94482aeca54b1fb511274"}},"metadata":{}},{"name":"stdout","text":"[CE VAL] Macro-F1=0.9559 Acc=0.9561\n  ↳ saved /kaggle/working/ce_gate_pipeline_v3/teacher.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[CE train ep3]:   0%|          | 0/2643 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11a90c1675f3473f94e4420b936b585c"}},"metadata":{}},{"name":"stdout","text":"[CE VAL] Macro-F1=0.9692 Acc=0.9693\n  ↳ saved /kaggle/working/ce_gate_pipeline_v3/teacher.pt\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[CE train ep4]:   0%|          | 0/2643 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2b442a6da9234e639da2ed45b11d7102"}},"metadata":{}},{"name":"stdout","text":"[CE VAL] Macro-F1=0.9740 Acc=0.9741\n  ↳ saved /kaggle/working/ce_gate_pipeline_v3/teacher.pt\nCE best F1: 0.9740049000280916\n","output_type":"stream"}],"execution_count":7},{"cell_type":"code","source":"class TempScaler(nn.Module):\n    def __init__(self): super().__init__(); self.t = nn.Parameter(torch.ones(1))\n    def forward(self, logits): return logits / self.t.clamp(0.5, 5.0)\n\nce.load_state_dict(torch.load(ce_ckpt, map_location=CFG.device))\nce.eval()\nall_logits, all_y = [], []\nwith torch.no_grad():\n    for batch in va_loader:\n        y = batch[\"labels\"].to(CFG.device)\n        enc = {k:v.to(CFG.device) for k,v in batch.items() if k!=\"labels\"}\n        lg = ce(enc)\n        all_logits.append(lg); all_y.append(y)\nall_logits = torch.cat(all_logits, 0)\nall_y = torch.cat(all_y, 0)\n\ntemp = TempScaler().to(CFG.device)\noptT = torch.optim.LBFGS(temp.parameters(), lr=0.1, max_iter=50)\ndef _closure():\n    optT.zero_grad()\n    loss = F.cross_entropy(temp(all_logits), all_y)\n    loss.backward()\n    return loss\noptT.step(_closure)\nT_value = float(temp.t.detach().cpu().clamp(0.5,5.0).item())\njson.dump({\"t\": T_value}, open(os.path.join(CFG.outdir, \"temp.json\"), \"w\"))\nprint(\"Fitted CE temperature:\", T_value)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T09:09:16.652249Z","iopub.execute_input":"2025-10-05T09:09:16.653143Z","iopub.status.idle":"2025-10-05T09:11:27.972743Z","shell.execute_reply.started":"2025-10-05T09:09:16.653118Z","shell.execute_reply":"2025-10-05T09:11:27.972038Z"}},"outputs":[{"name":"stdout","text":"Fitted CE temperature: 1.234139323234558\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"def load_temperature(path):\n    try:\n        return float(json.load(open(path,\"r\"))[\"t\"])\n    except Exception:\n        obj = torch.load(path, map_location=\"cpu\")\n        return float(obj[\"t\"])\n\nclass CE_Scorer:\n    def __init__(self, model_path, temperature_path):\n        self.model = CEModel(CFG.ce_backbone, 3, CFG.ce_dropout).to(CFG.device).eval()\n        self.model.load_state_dict(torch.load(model_path, map_location=CFG.device))\n        self.tok = tok_ce\n        self.T = load_temperature(temperature_path)\n\n    @torch.no_grad()\n    def score(self, A_list, B_list):\n        enc = self.tok(A_list, B_list, truncation=True, max_length=CFG.ce_max_len,\n                       padding=True, return_tensors=\"pt\")\n        enc = {k:v.to(CFG.device) for k,v in enc.items()}\n        logits = self.model(enc) / max(0.5, min(5.0, self.T))\n        return logits.softmax(-1).detach().cpu().numpy()  # [:,0]=E, [:,1]=N, [:,2]=C\n\nce_scorer = CE_Scorer(os.path.join(CFG.outdir,\"teacher.pt\"),\n                      os.path.join(CFG.outdir,\"temp.json\"))\n\ndef pack_dualbeam_pairaware(context: str, prompt: str, response: str) -> str:\n    sents = sent_tokenize_vi(context)\n    if not sents: return \"\"\n    PR = join_pr(prompt, response)\n    R, P = toks(response), toks(prompt)\n    W = [toks(s) for s in sents]\n    idf, avgdl = build_idf(W)\n\n    spans=[]\n    for k in CFG.span_sizes:\n        for st in range(0, len(sents), CFG.stride_sent):\n            en = min(len(sents), st+k)\n            if en<=st: continue\n            txt = \" \".join(sents[st:en]); ET = toks(txt)\n            slex = 0.5*(0.7*soft_char_overlap(R, ET) + 0.3*bm25_score(R, ET, idf, avgdl)) + \\\n                   0.5*(0.7*soft_char_overlap(P, ET) + 0.3*bm25_score(P, ET, idf, avgdl))\n            spans.append((st,en,txt,slex))\n    spans.sort(key=lambda x:x[3], reverse=True)\n    pool = spans[:min(CFG.top_span_pool, len(spans))]\n    if not pool:\n        ids = tok_pack.encode(context, add_special_tokens=False)[:EFFECTIVE_MAX_SINGLE]\n        return tok_pack.decode(ids, skip_special_tokens=True)\n\n    A = [PR]*len(pool); B = [x[2] for x in pool]\n    probs = ce_scorer.score(A,B)  # [:,0]=E, [:,1]=N, [:,2]=C\n\n    r_nums = numbers(response); rsp_neg = has_neg(response)\n    supp_list, conf_list = [], []\n    for (st,en,txt,sx), (pe,pn,pc) in zip(pool, probs):\n        t_nums = numbers(txt); txt_neg = has_neg(txt)\n        num_match_all = (r_nums and r_nums.issubset(t_nums))\n        num_mismatch  = (r_nums and t_nums and r_nums != t_nums)\n        neg_flip      = (rsp_neg != txt_neg)\n\n        supp = 0.75*pe - 0.25*pc + 0.10*sx\n        if num_match_all: supp += CFG.boost_num\n        if rsp_neg and txt_neg: supp += CFG.boost_neg\n\n        conf = 0.75*pc - 0.10*pe + 0.05*sx\n        if num_mismatch: conf += 0.25\n        if neg_flip:     conf += 0.20\n\n        supp_list.append((st,en,txt,sx,pe,pn,pc,supp))\n        conf_list.append((st,en,txt,sx,pe,pn,pc,conf))\n\n    supp_list.sort(key=lambda x: x[-1], reverse=True)\n    conf_list.sort(key=lambda x: x[-1], reverse=True)\n\n    used, mask = [], np.zeros(len(sents), dtype=int)\n    cur, budget = 0, EFFECTIVE_MAX_SINGLE\n    tgt_conf = CFG.conflict_target_ratio\n    pi, pj = 0, 0\n    conf_taken, total_taken = 0, 0\n\n    def try_take(item):\n        nonlocal cur\n        st,en,txt,*_ = item[:4]\n        tlen = len(tok_pack.encode(txt, add_special_tokens=False))\n        if cur + tlen > budget: return False\n        if mask[st:en].sum() > 0.5*(en-st): return False\n        used.append((st,en,txt,tlen)); mask[st:en]=1; cur+=tlen\n        return True\n\n    while (pi < len(supp_list) or pj < len(conf_list)) and cur < 0.9*budget:\n        ratio = (conf_taken/max(1,total_taken)) if total_taken>0 else 0.0\n        pick_conf = (ratio < tgt_conf)\n        took=False\n        if pick_conf and pj < len(conf_list):\n            if try_take(conf_list[pj]): conf_taken += 1; total_taken += 1; took=True\n            pj += 1\n        if not took and pi < len(supp_list):\n            if try_take(supp_list[pi]): total_taken += 1; took=True\n            pi += 1\n        if not took and pj < len(conf_list):\n            if try_take(conf_list[pj]): conf_taken += 1; total_taken += 1; took=True\n            pj += 1\n        if not took: break\n\n    if conf_taken == 0 and len(conf_list) > 0:\n        for item in conf_list:\n            if try_take(item): break\n\n    if not used:\n        st,en,txt,_ = pool[0]\n        ids = tok_pack.encode(txt, add_special_tokens=False)[:EFFECTIVE_MAX_SINGLE]\n        return tok_pack.decode(ids, skip_special_tokens=True)\n\n    used.sort(key=lambda x: x[0])\n    evi = \" \".join(u[2] for u in used)\n\n    rl = rouge_l_lcs(toks(response), toks(evi))\n    if rl < 0.18:\n        best = max(pool, key=lambda x: rouge_l_lcs(toks(response), toks(x[2])))\n        buf = tok_pack.encode(best[2], add_special_tokens=False)[:EFFECTIVE_MAX_SINGLE]\n        evi2 = tok_pack.decode(buf, skip_special_tokens=True)\n        if rouge_l_lcs(toks(response), toks(evi2)) > rl: evi = evi2\n    return evi","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T09:11:27.974411Z","iopub.execute_input":"2025-10-05T09:11:27.974611Z","iopub.status.idle":"2025-10-05T09:11:29.802753Z","shell.execute_reply.started":"2025-10-05T09:11:27.974596Z","shell.execute_reply":"2025-10-05T09:11:29.802210Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"def mass_from_evidence(context, prompt, response, evidence, topk=3):\n    sents = sent_tokenize_vi(evidence)\n    if not sents: return 0.0, 0.0, 0.0\n    PR = join_pr(prompt, response)\n    P = ce_scorer.score([PR]*len(sents), sents)   # [n,3] = E,N,C\n    k = min(topk, len(sents))\n    sup = float(np.mean(np.sort(P[:,0])[-k:]))\n    con = float(np.mean(np.sort(P[:,2])[-k:]))\n    neu = float(np.mean(np.sort(P[:,1])[-k:]))\n    return sup, con, neu\n\ndef analyze_packer(df, pack_fn, name, save_dir=CFG.outdir, include_label=True, limit=None):\n    rows=[]\n    it = range(len(df)) if limit is None else range(min(limit, len(df)))\n    for i in tqdm(it, desc=f\"[{name}] pack & score\"):\n        r = df.iloc[i]\n        ctx, prm, rsp = r[CFG.ctx_col], r[CFG.prm_col], r[CFG.rsp_col]\n        evi = pack_fn(ctx, prm, rsp)\n        rt, et = toks(rsp), toks(evi)\n        uni = len(set(rt)&set(et))/max(1,len(set(rt)|set(et)))\n        bi  = len(set(zip(rt,rt[1:])) & set(zip(et,et[1:]))) / \\\n              max(1, len(set(zip(rt,rt[1:])) | set(zip(et,et[1:]))))\n        rl  = rouge_l_lcs(rt, et)\n        if include_label:\n            rows.append([str(r[CFG.id_col]), str(r[CFG.lab_col]), evi, uni, bi, rl])\n        else:\n            rows.append([str(r[CFG.id_col]), evi, uni, bi, rl])\n\n    cols = [CFG.id_col, \"label\", \"evidence\", \"uni_cov\", \"bi_cov\", \"rougeL\"] if include_label \\\n           else [CFG.id_col, \"evidence\", \"uni_cov\", \"bi_cov\", \"rougeL\"]\n    dfm = pd.DataFrame(rows, columns=cols)\n    path = os.path.join(save_dir, f\"{name}_coverage.csv\")\n    dfm.to_csv(path, index=False)\n    print(\"Saved:\", path)\n    return dfm\n\ndef semantic_audit(df_raw, df_cov, split_name):\n    raw_ix = df_raw.set_index(CFG.id_col)\n    rows=[]\n    for _, row in tqdm(df_cov.iterrows(), total=len(df_cov), desc=f\"[semantic {split_name}]\"):\n        rid = str(row[CFG.id_col])\n        base = raw_ix.loc[rid]\n        sup, con, neu = mass_from_evidence(base[CFG.ctx_col], base[CFG.prm_col],\n                                           base[CFG.rsp_col], row[\"evidence\"], topk=3)\n        rows.append([rid, row.get(\"label\", None), sup, con, sup-con, neu, row[\"rougeL\"], row.get(\"uni_cov\", 0.0)])\n    sem = pd.DataFrame(rows, columns=[CFG.id_col,\"label\",\"support_mass\",\"conflict_mass\",\"gap\",\n                                      \"neutral_cov\",\"rougeL_ctx\",\"uni_cov_ctx\"])\n    out = os.path.join(CFG.outdir, f\"{split_name}_semantic.csv\"); sem.to_csv(out, index=False)\n    print(\"Saved:\", out)\n    return sem\n\ndef gate_report(sem_df, name=\"split\"):\n    print(f\"\\n=== Means by class ({name}) ===\")\n    print(sem_df.groupby(\"label\")[[\"support_mass\",\"conflict_mass\",\"neutral_cov\",\"uni_cov_ctx\",\"rougeL_ctx\"]].mean())\n    y_intr = (sem_df[\"label\"]==\"intrinsic\").astype(int).to_numpy()\n    y_ex   = (sem_df[\"label\"]==\"extrinsic\").astype(int).to_numpy()\n    auc_intr = roc_auc_score(y_intr, sem_df[\"conflict_mass\"].to_numpy())\n    auc_ex   = roc_auc_score(y_ex, (sem_df[\"neutral_cov\"] - sem_df[\"support_mass\"]).to_numpy())\n    rl_med   = float(sem_df[\"rougeL_ctx\"].median())\n    print(f\"AUC(intrinsic via conflict_mass) ≈ {auc_intr:.3f}\")\n    print(f\"AUC(extrinsic via neutral-support) ≈ {auc_ex:.3f}\")\n    print(f\"ROUGE-L median ≈ {rl_med:.3f}\")\n    return auc_intr, auc_ex, rl_med\n\ndef meta_decider_eval(sem_df, name=\"split\"):\n    X = sem_df[[\"support_mass\",\"conflict_mass\",\"neutral_cov\",\"rougeL_ctx\",\"uni_cov_ctx\"]].to_numpy()\n    y = sem_df[\"label\"].map(LABEL2ID).to_numpy()\n    clf = LogisticRegression(max_iter=200).fit(X,y)\n    pred = clf.predict(X)\n    f1 = f1_score(y, pred, average=\"macro\"); acc = accuracy_score(y,pred)\n    print(f\"[Meta-decider {name}] Macro-F1={f1:.4f} Acc={acc:.4f}\")\n    return clf, f1, acc\n\n# Split train/val và chạy\nsss = StratifiedShuffleSplit(n_splits=1, test_size=CFG.valid_ratio, random_state=CFG.seed)\ntr_idx, va_idx = next(sss.split(train_df, train_df[CFG.lab_col]))\ntr_df = train_df.iloc[tr_idx].reset_index(drop=True)\nva_df = train_df.iloc[va_idx].reset_index(drop=True)\n\ncov_tr = analyze_packer(tr_df, pack_dualbeam_pairaware, \"hybrid_train_v3\", include_label=True)\ncov_va = analyze_packer(va_df, pack_dualbeam_pairaware, \"hybrid_val_v3\",   include_label=True)\n\nsem_tr = semantic_audit(tr_df, cov_tr, \"train_v3\")\nsem_va = semantic_audit(va_df, cov_va, \"val_v3\")\n\nauc_tr_i, auc_tr_e, rl_tr = gate_report(sem_tr, \"train_v3\")\nauc_va_i, auc_va_e, rl_va = gate_report(sem_va, \"val_v3\")\n\nmeta_tr, f1_tr, _ = meta_decider_eval(sem_tr, \"train_v3\")\nmeta_va, f1_va, _ = meta_decider_eval(sem_va, \"val_v3\")\n\ngate_ok = bool(\n    float(auc_va_i) >= float(CFG.auc_intrinsic_min) and\n    float(auc_va_e) >= float(CFG.auc_extrinsic_min) and\n    float(f1_va)    >= float(CFG.meta_f1_min)       and\n    float(rl_va)    >= float(CFG.rl_median_min)\n)\n\njson.dump({\n    \"auc_intr_train\": float(auc_tr_i),\n    \"auc_extr_train\": float(auc_tr_e),\n    \"rl_med_train\":   float(rl_tr),\n    \"auc_intr_val\":   float(auc_va_i),\n    \"auc_extr_val\":   float(auc_va_e),\n    \"rl_med_val\":     float(rl_va),\n    \"meta_f1_train\":  float(f1_tr),\n    \"meta_f1_val\":    float(f1_va),\n    \"gate_pass\":      bool(gate_ok),\n}, open(os.path.join(CFG.outdir, \"gate_report.json\"), \"w\"), ensure_ascii=False, indent=2)\n\nprint(\"\\n[GATE] PASS? \", gate_ok,\n      f\"(AUC_i {auc_va_i:.3f} / {CFG.auc_intrinsic_min}, AUC_e {auc_va_e:.3f} / {CFG.auc_extrinsic_min}, \"\n      f\"F1_meta {f1_va:.3f} / {CFG.meta_f1_min}, RL_med {rl_va:.3f} / {CFG.rl_median_min})\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T09:11:29.803540Z","iopub.execute_input":"2025-10-05T09:11:29.803791Z","iopub.status.idle":"2025-10-05T10:06:10.867777Z","shell.execute_reply.started":"2025-10-05T09:11:29.803771Z","shell.execute_reply":"2025-10-05T10:06:10.867095Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"[hybrid_train_v3] pack & score:   0%|          | 0/6300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b6214eb0838547468aa28919415ef173"}},"metadata":{}},{"name":"stdout","text":"Saved: /kaggle/working/ce_gate_pipeline_v3/hybrid_train_v3_coverage.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[hybrid_val_v3] pack & score:   0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0e6b44b4599404894293787dd987370"}},"metadata":{}},{"name":"stdout","text":"Saved: /kaggle/working/ce_gate_pipeline_v3/hybrid_val_v3_coverage.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[semantic train_v3]:   0%|          | 0/6300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ab1bc272d11842f3bae97cac743a75fb"}},"metadata":{}},{"name":"stdout","text":"Saved: /kaggle/working/ce_gate_pipeline_v3/train_v3_semantic.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[semantic val_v3]:   0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"de37a29f6d754ba893253a28dcb91777"}},"metadata":{}},{"name":"stdout","text":"Saved: /kaggle/working/ce_gate_pipeline_v3/val_v3_semantic.csv\n\n=== Means by class (train_v3) ===\n           support_mass  conflict_mass  neutral_cov  uni_cov_ctx  rougeL_ctx\nlabel                                                                       \nextrinsic      0.258124       0.321481     0.509798     0.248837    0.235355\nintrinsic      0.037195       0.359927     0.660521     0.274342    0.254092\nno             0.984094       0.006603     0.016470     0.332091    0.317218\nAUC(intrinsic via conflict_mass) ≈ 0.667\nAUC(extrinsic via neutral-support) ≈ 0.625\nROUGE-L median ≈ 0.242\n\n=== Means by class (val_v3) ===\n           support_mass  conflict_mass  neutral_cov  uni_cov_ctx  rougeL_ctx\nlabel                                                                       \nextrinsic      0.294229       0.293933     0.521417     0.248871    0.238094\nintrinsic      0.033143       0.373569     0.647033     0.268434    0.245356\nno             0.980133       0.009732     0.016447     0.331816    0.312170\nAUC(intrinsic via conflict_mass) ≈ 0.692\nAUC(extrinsic via neutral-support) ≈ 0.620\nROUGE-L median ≈ 0.242\n[Meta-decider train_v3] Macro-F1=0.7792 Acc=0.7851\n[Meta-decider val_v3] Macro-F1=0.7847 Acc=0.7986\n\n[GATE] PASS?  False (AUC_i 0.692 / 0.74, AUC_e 0.620 / 0.66, F1_meta 0.785 / 0.74, RL_med 0.242 / 0.2)\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"def attach_mass(df_raw, df_cov, split_name):\n    raw_ix = df_raw.set_index(CFG.id_col)\n    rows=[]\n    for _, row in tqdm(df_cov.iterrows(), total=len(df_cov), desc=f\"[attach mass {split_name}]\"):\n        rid = str(row[CFG.id_col])\n        base = raw_ix.loc[rid]\n        sup, con, neu = mass_from_evidence(base[CFG.ctx_col], base[CFG.prm_col],\n                                           base[CFG.rsp_col], row[\"evidence\"], topk=3)\n        rows.append([rid, sup, con, neu])\n    massdf = pd.DataFrame(rows, columns=[CFG.id_col,\"support_mass\",\"conflict_mass\",\"neutral_cov\"])\n    merged = df_cov.merge(massdf, on=CFG.id_col, how=\"left\")\n    path = os.path.join(CFG.outdir, f\"{split_name}_coverage_with_mass.csv\")\n    merged.to_csv(path, index=False)\n    print(\"Saved:\", path)\n    return merged\n\ncov_tr_m = attach_mass(tr_df, cov_tr, \"hybrid_train_v3\")\ncov_va_m = attach_mass(va_df, cov_va, \"hybrid_val_v3\")\n\n# TEST coverage + mass (không có label, có cột id gốc)\ncov_te = analyze_packer(test_df, pack_dualbeam_pairaware, \"hybrid_test_v3\", include_label=False)\nraw_ix_te = test_df.set_index(CFG.id_col)\nrows=[]\nfor _, row in tqdm(cov_te.iterrows(), total=len(cov_te), desc=\"[attach mass TEST]\"):\n    rid = str(row[CFG.id_col])\n    base = raw_ix_te.loc[rid]\n    sup, con, neu = mass_from_evidence(base[CFG.ctx_col], base[CFG.prm_col],\n                                       base[CFG.rsp_col], row[\"evidence\"], topk=3)\n    rows.append([rid, sup, con, neu])\nmass_te = pd.DataFrame(rows, columns=[CFG.id_col,\"support_mass\",\"conflict_mass\",\"neutral_cov\"])\ncov_te_m = cov_te.merge(mass_te, on=CFG.id_col, how=\"left\")\nout_test = os.path.join(CFG.outdir, \"hybrid_test_v3_coverage_with_mass.csv\")\ncov_te_m.to_csv(out_test, index=False)\nprint(\"Saved TEST coverage+mass:\", out_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T10:06:10.868467Z","iopub.execute_input":"2025-10-05T10:06:10.868711Z","iopub.status.idle":"2025-10-05T10:24:55.966566Z","shell.execute_reply.started":"2025-10-05T10:06:10.868691Z","shell.execute_reply":"2025-10-05T10:24:55.965948Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"[attach mass hybrid_train_v3]:   0%|          | 0/6300 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0676bc187db345fca138bca78d108acd"}},"metadata":{}},{"name":"stdout","text":"Saved: /kaggle/working/ce_gate_pipeline_v3/hybrid_train_v3_coverage_with_mass.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[attach mass hybrid_val_v3]:   0%|          | 0/700 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d54f1912272d4fe1b89e5ed30d45e620"}},"metadata":{}},{"name":"stdout","text":"Saved: /kaggle/working/ce_gate_pipeline_v3/hybrid_val_v3_coverage_with_mass.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[hybrid_test_v3] pack & score:   0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4f81ebb9d6b54bafbec3aa6135249a7c"}},"metadata":{}},{"name":"stdout","text":"Saved: /kaggle/working/ce_gate_pipeline_v3/hybrid_test_v3_coverage.csv\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"[attach mass TEST]:   0%|          | 0/2000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1b0ad437f1824927af9d81bbfcaddde5"}},"metadata":{}},{"name":"stdout","text":"Saved TEST coverage+mass: /kaggle/working/ce_gate_pipeline_v3/hybrid_test_v3_coverage_with_mass.csv\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# label map\njson.dump({\"LABEL2ID\": LABEL2ID, \"ID2LABEL\": ID2LABEL},\n          open(os.path.join(CFG.outdir, \"labels.json\"), \"w\"),\n          ensure_ascii=False, indent=2)\n\nartifacts = {\n    \"teacher_ckpt\": \"teacher.pt\",\n    \"teacher_temp\": \"temp.json\",\n    \"pairs_raw\": \"ce_pairs_raw.csv\",\n    \"pairs_balanced\": \"ce_pairs_balanced.csv\",\n    \"coverage_train\": \"hybrid_train_v3_coverage.csv\",\n    \"coverage_val\": \"hybrid_val_v3_coverage.csv\",\n    \"semantic_train\": \"train_v3_semantic.csv\",\n    \"semantic_val\": \"val_v3_semantic.csv\",\n    \"coverage_train_with_mass\": \"hybrid_train_v3_coverage_with_mass.csv\",\n    \"coverage_val_with_mass\": \"hybrid_val_v3_coverage_with_mass.csv\",\n    \"coverage_test_with_mass\": \"hybrid_test_v3_coverage_with_mass.csv\",\n    \"gate_report\": \"gate_report.json\",\n    \"label_map\": \"labels.json\",\n}\n\njson.dump({\"artifacts\": artifacts,\n           \"notes\": \"All coverage/mass files are keyed by the RAW id (no idx).\"},\n          open(os.path.join(CFG.outdir, \"MANIFEST.json\"), \"w\"),\n          ensure_ascii=False, indent=2)\n\nreadme = f\"\"\"\nArtifacts to reuse in the classifier notebook:\n\n- CE teacher: teacher.pt (+ temp.json)\n- Packer coverage (id-based): hybrid_train_v3_coverage.csv, hybrid_val_v3_coverage.csv\n- Semantic: train_v3_semantic.csv, val_v3_semantic.csv\n- Coverage+mass (id-based): hybrid_*_coverage_with_mass.csv (train/val/test)\n- Gate report: gate_report.json\n- Label maps: labels.json\n\nAll files are joined by RAW '{CFG.id_col}' — no 'idx' used anywhere.\n\"\"\"\nopen(os.path.join(CFG.outdir, \"README.txt\"), \"w\", encoding=\"utf-8\").write(readme)\n\nprint(\"Saved MANIFEST & README to:\", CFG.outdir)\nprint(json.dumps(artifacts, indent=2))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T10:24:55.967477Z","iopub.execute_input":"2025-10-05T10:24:55.967793Z","iopub.status.idle":"2025-10-05T10:24:55.976410Z","shell.execute_reply.started":"2025-10-05T10:24:55.967766Z","shell.execute_reply":"2025-10-05T10:24:55.975343Z"}},"outputs":[{"name":"stdout","text":"Saved MANIFEST & README to: /kaggle/working/ce_gate_pipeline_v3\n{\n  \"teacher_ckpt\": \"teacher.pt\",\n  \"teacher_temp\": \"temp.json\",\n  \"pairs_raw\": \"ce_pairs_raw.csv\",\n  \"pairs_balanced\": \"ce_pairs_balanced.csv\",\n  \"coverage_train\": \"hybrid_train_v3_coverage.csv\",\n  \"coverage_val\": \"hybrid_val_v3_coverage.csv\",\n  \"semantic_train\": \"train_v3_semantic.csv\",\n  \"semantic_val\": \"val_v3_semantic.csv\",\n  \"coverage_train_with_mass\": \"hybrid_train_v3_coverage_with_mass.csv\",\n  \"coverage_val_with_mass\": \"hybrid_val_v3_coverage_with_mass.csv\",\n  \"coverage_test_with_mass\": \"hybrid_test_v3_coverage_with_mass.csv\",\n  \"gate_report\": \"gate_report.json\",\n  \"label_map\": \"labels.json\"\n}\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# Cần thêm dataset chứa file /kaggle/input/kaggle-json/kaggle.json\nimport subprocess, shutil, stat\n\nDATA_DIR = CFG.outdir\nMETA = {\n  \"title\": \"CE Gate Pipeline v32 (teacher+coverage+mass)\",\n  \"id\": \"honghien123/ce-gate-pipeline-v3-3\",\n  \"licenses\": [{\"name\": \"CC0-1.0\"}],\n  \"isPrivate\": True\n}\nopen(os.path.join(DATA_DIR, \"dataset-metadata.json\"), \"w\").write(json.dumps(META, ensure_ascii=False, indent=2))\n\ndef run(cmd):\n    r = subprocess.run(cmd, capture_output=True, text=True)\n    print(r.stdout or r.stderr)\n    return r.returncode\n\ntry:\n    os.makedirs(\"/root/.kaggle\", exist_ok=True)\n    shutil.copy(\"/kaggle/input/kaggle-json-2/kaggle.json\", \"/root/.kaggle/kaggle.json\")\n    os.chmod(\"/root/.kaggle/kaggle.json\", stat.S_IRUSR | stat.S_IWUSR)\n    rc = run([\"kaggle\", \"datasets\", \"create\", \"-p\", DATA_DIR, \"-r\", \"zip\"])\n    if rc != 0:\n        run([\"kaggle\", \"datasets\", \"version\", \"-p\", DATA_DIR, \"-m\", \"update\"])\nexcept Exception as e:\n    print(\"Skip Kaggle CLI publish:\", e)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-10-05T10:39:16.110619Z","iopub.execute_input":"2025-10-05T10:39:16.111254Z","iopub.status.idle":"2025-10-05T10:39:42.838184Z","shell.execute_reply.started":"2025-10-05T10:39:16.111228Z","shell.execute_reply":"2025-10-05T10:39:42.837444Z"}},"outputs":[{"name":"stdout","text":"Starting upload for file gate_report.json\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: gate_report.json (331B)\nStarting upload for file hybrid_train_v3_coverage_with_mass.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: hybrid_train_v3_coverage_with_mass.csv (4MB)\nStarting upload for file MANIFEST.json\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: MANIFEST.json (727B)\nStarting upload for file labels.json\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: labels.json (154B)\nStarting upload for file temp.json\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: temp.json (24B)\nStarting upload for file hybrid_test_v3_coverage_with_mass.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: hybrid_test_v3_coverage_with_mass.csv (1MB)\nStarting upload for file hybrid_val_v3_coverage_with_mass.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: hybrid_val_v3_coverage_with_mass.csv (488KB)\nStarting upload for file README.txt\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: README.txt (427B)\nStarting upload for file hybrid_val_v3_coverage.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: hybrid_val_v3_coverage.csv (446KB)\nStarting upload for file hybrid_test_v3_coverage.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: hybrid_test_v3_coverage.csv (1MB)\nStarting upload for file val_v3_semantic.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: val_v3_semantic.csv (112KB)\nStarting upload for file ce_pairs_raw.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: ce_pairs_raw.csv (97MB)\nStarting upload for file hybrid_train_v3_coverage.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: hybrid_train_v3_coverage.csv (4MB)\nStarting upload for file ce_pairs_balanced.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: ce_pairs_balanced.csv (78MB)\nStarting upload for file teacher.pt\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: teacher.pt (1GB)\nStarting upload for file train_v3_semantic.csv\nError while trying to load upload info: ApiStartBlobUploadRequest.__init__() got an unexpected keyword argument 'type'\nUpload successful: train_v3_semantic.csv (1006KB)\nYour private Dataset is being created. Please check progress at https://www.kaggle.com/datasets/honghien123/ce-gate-pipeline-v3-3\n\n","output_type":"stream"}],"execution_count":16}]}